{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b73881",
   "metadata": {},
   "source": [
    "## 1. Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe93a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d95571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad8462",
   "metadata": {},
   "source": [
    "## 2. Import Data using Image Augumentation\n",
    "Image augmentation is a technique of **altering the existing data to create some more data** for the model training process. \n",
    "In other words, it is the process of **artificially expanding the available dataset** for training a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "438ddd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebcf143",
   "metadata": {},
   "source": [
    "#### Step 1 : Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583028be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data       = ImageDataGenerator(horizontal_flip=True,vertical_flip=True,rescale=1./255,shear_range=0.02,zoom_range=0.02,)\n",
    "validation_data  = ImageDataGenerator(rescale=1./255)\n",
    "test_data        = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd84405",
   "metadata": {},
   "source": [
    "#### Step 2 : Mention the path of train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784e7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 110 images belonging to 5 classes.\n",
      "Found 53 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_x_y      = train_data.flow_from_directory(directory = r'D:\\DLCVNLP\\Parent', target_size=(256, 256))\n",
    "validation_x_y = validation_data.flow_from_directory(directory = r'D:\\DLCVNLP\\Validation_data', target_size=(256, 256))                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5134128b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iyan': 0, 'john': 1, 'mary': 2, 'superman': 3, 'suresh': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_y.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6c071",
   "metadata": {},
   "source": [
    "## 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62f050e",
   "metadata": {},
   "source": [
    "#### Step 1: Build the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ce1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1818b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 524288)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               104857800 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1005      \n",
      "=================================================================\n",
      "Total params: 104,859,701\n",
      "Trainable params: 104,859,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32,kernel_size = (3,3),strides = 1,padding = 'same',activation = 'relu',input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2),strides = 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 200,activation = 'relu'))\n",
    "model.add(Dense(units = 5,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2faec22",
   "metadata": {},
   "source": [
    "#### Step No 2 : Compile your architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c5e9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer='adam',loss=['categorical_crossentropy'],metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16238108",
   "metadata": {},
   "source": [
    "#### Step 3 : Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bfd80ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 43s 28s/step - loss: 62.5861 - categorical_accuracy: 0.1562 - val_loss: 120.7931 - val_categorical_accuracy: 0.1321\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 36s 24s/step - loss: 45.9370 - categorical_accuracy: 0.4062 - val_loss: 30.2236 - val_categorical_accuracy: 0.0377\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 31s 18s/step - loss: 51.2744 - categorical_accuracy: 0.1957 - val_loss: 17.5396 - val_categorical_accuracy: 0.6226\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 37s 26s/step - loss: 29.1790 - categorical_accuracy: 0.2344 - val_loss: 23.4347 - val_categorical_accuracy: 0.1887\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 30s 25s/step - loss: 16.2367 - categorical_accuracy: 0.3913 - val_loss: 38.7827 - val_categorical_accuracy: 0.1887\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 32s 17s/step - loss: 9.3923 - categorical_accuracy: 0.4565 - val_loss: 35.8264 - val_categorical_accuracy: 0.2075\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 31s 18s/step - loss: 8.3648 - categorical_accuracy: 0.6304 - val_loss: 25.0041 - val_categorical_accuracy: 0.1509\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 36s 23s/step - loss: 6.4194 - categorical_accuracy: 0.4688 - val_loss: 19.9318 - val_categorical_accuracy: 0.1132\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 32s 25s/step - loss: 3.0931 - categorical_accuracy: 0.5217 - val_loss: 14.0990 - val_categorical_accuracy: 0.1509\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 37s 23s/step - loss: 3.0005 - categorical_accuracy: 0.6406 - val_loss: 9.2626 - val_categorical_accuracy: 0.3019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2c0d09fa0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_x_y,epochs=10,validation_data=validation_x_y,steps_per_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893aa87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
